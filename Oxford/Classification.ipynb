{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## library import\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory 설정\n",
    "data_dir = 'C:/Users/user/Desktop/data/Oxford_Petdataset'\n",
    "image_dir = os.path.join(data_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7378\n"
     ]
    }
   ],
   "source": [
    "## image file 수 확인\n",
    "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image file들을 읽어서 channel이 3이 아닌 image는 삭제\n",
    "for image_file in image_files:\n",
    "  image_path = os.path.join(image_dir, image_file)\n",
    "  image = Image.open(image_path)\n",
    "  image_mode = image.mode\n",
    "  if image_mode != 'RGB':\n",
    "    print(image_file, image_mode)\n",
    "    image = np.asarray(image)\n",
    "    print(image.shape)\n",
    "    os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7378\n"
     ]
    }
   ],
   "source": [
    "## image file 수 확인\n",
    "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "class_list = set()\n",
    "for image_file in image_files:\n",
    "    file_name = os.path.splitext(image_file)[0]\n",
    "    class_name = re.sub('_\\d+', '', file_name)\n",
    "    class_list.add(class_name)\n",
    "class_list = list(class_list)\n",
    "print(len(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinian',\n",
       " 'Bengal',\n",
       " 'Birman',\n",
       " 'Bombay',\n",
       " 'British_Shorthair',\n",
       " 'Egyptian_Mau',\n",
       " 'Maine_Coon',\n",
       " 'Persian',\n",
       " 'Ragdoll',\n",
       " 'Russian_Blue',\n",
       " 'Siamese',\n",
       " 'Sphynx',\n",
       " 'american_bulldog',\n",
       " 'american_pit_bull_terrier',\n",
       " 'basset_hound',\n",
       " 'beagle',\n",
       " 'boxer',\n",
       " 'chihuahua',\n",
       " 'english_cocker_spaniel',\n",
       " 'english_setter',\n",
       " 'german_shorthaired',\n",
       " 'great_pyrenees',\n",
       " 'havanese',\n",
       " 'japanese_chin',\n",
       " 'keeshond',\n",
       " 'leonberger',\n",
       " 'miniature_pinscher',\n",
       " 'newfoundland',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'saint_bernard',\n",
       " 'samoyed',\n",
       " 'scottish_terrier',\n",
       " 'shiba_inu',\n",
       " 'staffordshire_bull_terrier',\n",
       " 'wheaten_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list.sort()\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abyssinian': 0,\n",
       " 'Bengal': 1,\n",
       " 'Birman': 2,\n",
       " 'Bombay': 3,\n",
       " 'British_Shorthair': 4,\n",
       " 'Egyptian_Mau': 5,\n",
       " 'Maine_Coon': 6,\n",
       " 'Persian': 7,\n",
       " 'Ragdoll': 8,\n",
       " 'Russian_Blue': 9,\n",
       " 'Siamese': 10,\n",
       " 'Sphynx': 11,\n",
       " 'american_bulldog': 12,\n",
       " 'american_pit_bull_terrier': 13,\n",
       " 'basset_hound': 14,\n",
       " 'beagle': 15,\n",
       " 'boxer': 16,\n",
       " 'chihuahua': 17,\n",
       " 'english_cocker_spaniel': 18,\n",
       " 'english_setter': 19,\n",
       " 'german_shorthaired': 20,\n",
       " 'great_pyrenees': 21,\n",
       " 'havanese': 22,\n",
       " 'japanese_chin': 23,\n",
       " 'keeshond': 24,\n",
       " 'leonberger': 25,\n",
       " 'miniature_pinscher': 26,\n",
       " 'newfoundland': 27,\n",
       " 'pomeranian': 28,\n",
       " 'pug': 29,\n",
       " 'saint_bernard': 30,\n",
       " 'samoyed': 31,\n",
       " 'scottish_terrier': 32,\n",
       " 'shiba_inu': 33,\n",
       " 'staffordshire_bull_terrier': 34,\n",
       " 'wheaten_terrier': 35,\n",
       " 'yorkshire_terrier': 36}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n",
    "class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2idx['Bengal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train, validation directory 생성\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinian_1.jpg',\n",
       " 'Abyssinian_10.jpg',\n",
       " 'Abyssinian_100.jpg',\n",
       " 'Abyssinian_101.jpg',\n",
       " 'Abyssinian_102.jpg',\n",
       " 'Abyssinian_103.jpg',\n",
       " 'Abyssinian_104.jpg',\n",
       " 'Abyssinian_105.jpg',\n",
       " 'Abyssinian_106.jpg',\n",
       " 'Abyssinian_107.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "previous_class = \"\"\n",
    "for image_file in image_files:\n",
    "    file_name = os.path.splitext(image_file)[0]\n",
    "    class_name = re.sub('_\\d+', '', file_name)\n",
    "    if class_name == previous_class:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        cnt = 1\n",
    "    if cnt <= 160:\n",
    "        cpath = train_dir\n",
    "    else:\n",
    "        cpath = val_dir\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    shutil.copy(image_path, cpath)\n",
    "    previous_class = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir(train_dir)\n",
    "val_images = os.listdir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5920 1458\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images), len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord File 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFRecord 저장할 directory와 file 경로 설정\n",
    "tfr_dir = os.path.join(data_dir, 'tfrecord')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'cls_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'cls_val.tfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFRecord writer 생성\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5920\n"
     ]
    }
   ],
   "source": [
    "## Training data로 tfrecord 만들기\n",
    "n_train = 0\n",
    "\n",
    "train_files = os.listdir(train_dir)\n",
    "for train_file in train_files:\n",
    "  train_path = os.path.join(train_dir, train_file)\n",
    "  image = Image.open(train_path)\n",
    "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "  bimage = image.tobytes()\n",
    "\n",
    "  file_name = os.path.splitext(train_file)[0] #Bangal_101\n",
    "  class_name = re.sub('_\\d+', '', file_name)\n",
    "  class_num = class2idx[class_name]\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image': _bytes_feature(bimage),\n",
    "      'cls_num': _int64_feature(class_num)\n",
    "  }))\n",
    "  writer_train.write(example.SerializeToString())\n",
    "  n_train += 1\n",
    "\n",
    "writer_train.close()\n",
    "print(n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n"
     ]
    }
   ],
   "source": [
    "## Validation data로 tfrecord 만들기\n",
    "n_val = 0\n",
    "\n",
    "val_files = os.listdir(val_dir)\n",
    "for val_file in val_files:\n",
    "  val_path = os.path.join(val_dir, val_file)\n",
    "  image = Image.open(val_path)\n",
    "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "  bimage = image.tobytes()\n",
    "\n",
    "  file_name = os.path.splitext(val_file)[0] #Bangal_101\n",
    "  class_name = re.sub('_\\d+', '', file_name)\n",
    "  class_num = class2idx[class_name]\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image': _bytes_feature(bimage),\n",
    "      'cls_num': _int64_feature(class_num)\n",
    "  }))\n",
    "  writer_val.write(example.SerializeToString())\n",
    "  n_val += 1\n",
    "\n",
    "writer_val.close()\n",
    "print(n_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameters\n",
    "N_CLASS = len(class_list)\n",
    "N_EPOCHS = 20\n",
    "N_BATCH = 40\n",
    "N_TRAIN = n_train\n",
    "N_VAL = n_val\n",
    "IMG_SIZE = 224\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = N_TRAIN / N_BATCH\n",
    "validation_steps = int(np.ceil(N_VAL / N_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file을 data로 parsing해주는 function\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
    "              'cls_num': tf.io.FixedLenFeature([], tf.int64)              \n",
    "             }\n",
    "    print(features)\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "    print(parsed_features)\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n",
    "    print(image)\n",
    "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
    "    image = tf.cast(image, tf.float32)/255. \n",
    "    print(image)\n",
    "    label = tf.cast(parsed_features['cls_num'], tf.int64)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': FixedLenFeature(shape=[], dtype=tf.string, default_value=None), 'cls_num': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "{'cls_num': <tf.Tensor 'ParseSingleExample/ParseExample/ParseExampleV2:0' shape=() dtype=int64>, 'image': <tf.Tensor 'ParseSingleExample/ParseExample/ParseExampleV2:1' shape=() dtype=string>}\n",
      "Tensor(\"DecodeRaw:0\", shape=(None,), dtype=uint8)\n",
      "Tensor(\"truediv:0\", shape=(224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## train dataset 만들기\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(N_TRAIN).prefetch(\n",
    "    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9652531e86fbc99dfe7fc5092eb81081a97fad237de3d1fd3b3a0d1c69c61538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ox': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
